language: c

branches:
  only:
    - master
    - /^maintenance_[0-9]+\.[0-9]+\.x$/

sudo: false

matrix:
  include:
    # do one build run with our minimum dependencies
    # (or, well, at least the lowest version number that is available through
    #  anaconda..)
    - os: linux
      env: PYTHON_VERSION=2.7 MINIMUM_DEPENDENCIES="True"
    - os: linux
      env: PYTHON_VERSION=2.7
    - os: linux
      env: PYTHON_VERSION=3.4
    - os: linux
      env: PYTHON_VERSION=3.5
    - os: linux
      env: PYTHON_VERSION=3.6
    - os: linux
      env: PYTHON_VERSION=3.7
    # - os: linux
    #   env: PYTHON_VERSION=3.5 ARCHITECTURE_32BIT="True"
    #   addons:
    #     apt:
    #       packages:
    #         # https://github.com/travis-ci/apt-package-whitelist/blob/master/ubuntu-precise
    #         - libstdc++6:i386
    #         - gcc-multilib
    - os: osx
      env: PYTHON_VERSION=2.7
    - os: osx
      env: PYTHON_VERSION=3.6
    - os: osx
      env: PYTHON_VERSION=3.7

# mimick travis fast fail and rolling build setup from:
# https://github.com/JuliaLang/julia/blob/master/.travis.yml
before_install:
  - if [ `uname` = "Darwin" ]; then brew update; brew install -v jq; fi
  - curl "https://raw.githubusercontent.com/JuliaLang/julia/master/contrib/travis_fastfail.sh" -o "/tmp/fastfail.sh" || echo "Failed to fetch travis_fastfail.sh"
  - if [ -f /tmp/fastfail.sh ]; then chmod u+x /tmp/fastfail.sh; /tmp/fastfail.sh || exit 1; fi

install:
  - if [[ "$TRAVIS_OS_NAME" == "osx" ]]; then
      export OS="MacOSX";
    else
      export OS="Linux";
    fi
  # - |
  # -   if [[ "$ARCHITECTURE_32BIT" == "True" ]]; then
  # -     export ARCH=""
  # -     # OPT is used by setuptools patches contained in newer numpy versions
  # -     # used by obspy when running pip install --no-deps .
  # -     export OPT="-m32"
  # -     # workaround for sudo dpkg --add-architecture i386
  # -     # be sure multiarch is the only file in this directory
  # -     ls /etc/dpkg/dpkg.cfg.d/
  # -     # multiarch must contain foreign-architecture i386. If not it will
  # -     # error later and you need to do the following and add sudo: true
  # -     #sudo sh -c "echo 'foreign-architecture i386' > /etc/dpkg/dpkg.cfg.d/multiarch"
  # -     cat /etc/dpkg/dpkg.cfg.d/multiarch
  # -   else
  # -     export ARCH="_64"
  # -   fi
  - export ARCH="_64"
  - if [[ "${PYTHON_VERSION:0:1}" == '2' ]]; then
      wget https://repo.continuum.io/miniconda/Miniconda2-latest-${OS}-x86${ARCH}.sh -O miniconda.sh;
    else
      wget https://repo.continuum.io/miniconda/Miniconda3-latest-${OS}-x86${ARCH}.sh -O miniconda.sh;
    fi
  - bash miniconda.sh -b -p $HOME/miniconda
  - export PATH="$HOME/miniconda/bin:$PATH"
  - hash -r
  - conda config --set always_yes yes --set changeps1 no
  - conda update -q conda
  # Useful for debugging any issues with conda
  - conda info -a
  - |
      if [[ "$MINIMUM_DEPENDENCIES" == 'True' ]]; then
        NUMPY="numpy=1.6.2"
        SCIPY="scipy=0.11.0"
        MATPLOTLIB="matplotlib=1.1.1"
        # no basemap version works with this old numpy, so leave out
        BASEMAP=""
        PYPROJ="pyproj"
        PROJ4="proj4"
        # ancient matplotlib needs to be turned to AGG before anything else,
        # otherwise it tries to import incompatible version of Qt as a backend
        # and hick-ups..
        mkdir -p $HOME/.matplotlib
        echo 'backend:AGG' > $HOME/.matplotlib/matplotlibrc
      elif [[ "${PYTHON_VERSION}" == '3.4' ]]; then
        # 3.4 apparently no longer get's updated packages.
        # Let conda resolve to the latest versions.
        NUMPY="numpy"
        SCIPY="scipy"
        MATPLOTLIB="matplotlib"
        BASEMAP="basemap"
        PYPROJ="pyproj"
        PROJ4="proj4"
      # elif [[ "$ARCHITECTURE_32BIT" == "True" ]]; then
      #   # Special packages for 32bit. Also let conda resolve to the latest
      #   # versions.
      #   NUMPY="numpy"
      #   SCIPY="scipy"
      #   MATPLOTLIB="matplotlib"
      #   BASEMAP="basemap"
      #   PYPROJ="pyproj"
      # For anything else also let conda resolve, but force matplotlib 2.
      elif [[ "${PYTHON_VERSION}" == '3.6' ]]; then
        # Pin proj4 to 4.9.3 for map testing - see basemap #433
        # Let conda resolve to the latest versions otherwise.
        NUMPY="numpy"
        SCIPY="scipy"
        MATPLOTLIB="matplotlib"
        BASEMAP="basemap"
        PYPROJ="pyproj"
        PROJ4="proj4=4.9.3"
      else
        NUMPY="numpy"
        SCIPY="scipy"
        MATPLOTLIB="matplotlib>=2.0.0"
        BASEMAP="basemap"
        PYPROJ="pyproj"
        PROJ4="proj4"
      fi
  - |
    if [[ "${PYTHON_VERSION}" == '3.7' ]]; then
      FREETYPE="freetype"
    else
      FREETYPE="freetype<2.8"
    fi
  # proj4 version 5.2.0 has issues with psuedocyl projections (see basemap #433).
  - conda create -q -n test-environment
        python=$PYTHON_VERSION
        $NUMPY
        $SCIPY
        $MATPLOTLIB
        $BASEMAP
        $PYPROJ
        $PROJ4
        coverage
        decorator
        docopt
        future
        jsonschema
        lxml
        mock
        nose
        requests
        sqlalchemy
        $FREETYPE
        cryptography
  - source activate test-environment
  # additional, optional packages that run some more tests but are not
  # available for all archs. "--no-update-dependencies" keeps other packages at
  # already installed version (ideally we should handle package versions
  # through pinning or an environment file..)
  #- conda config --add channels conda-forge
  # XXX for now don't try to install other optional dependencies so that at
  # least our builds work..
  # XXX - conda install --no-update-dependencies m2crypto || true
  # XXX - conda install --no-update-dependencies cartopy || true
  # pyshp is safe to install, it depends on no other packages and has a noarch
  # py6 package
  # not a clue why conda is trying to pull in other packages when doing
  # "conda install -c conda-forge --no-update-dependencies pyshp", because the
  # pyshp conda package lists 0 dependencies, anyway, so use "--no-deps" to
  # really avoid installing/updating any other packages
  - conda install -c conda-forge --no-update-deps --no-deps pyshp || pip install pyshp
  # install packages not available via conda
  - pip install codecov
  - pip install geographiclib
  # current pyimgur stable release has a py3 incompatibility
  - pip install https://github.com/megies/PyImgur/archive/py3.zip
  - pip freeze
  - pip install https://github.com/obspy/obspy_github_api/archive/0.7.0.zip
  - conda list
  # done installing dependencies
  - git version
  - git fetch origin --tags --unshallow
  - git remote add obspy git://github.com/obspy/obspy.git
  - git fetch obspy --tags
  - git status
  - git branch -vv
  - git remote -vv
  # try to set correct remote tracking branch (to get branch info in version number of reports at tests.obspy.org)
  - |
      if [ "$TRAVIS_PULL_REQUEST" != "false" ]
        # we're building a pull request, so we need to find out the fork it's coming from through github API
        then GITHUB_LABEL=`python -c "from urllib import urlopen; import json; print(json.loads(urlopen(\"https://api.github.com/repos/$TRAVIS_REPO_SLUG/pulls/$TRAVIS_PULL_REQUEST\").read()).get('head').get('label'))"`
             export GITHUB_FORK=${GITHUB_LABEL%:*}
             export GITHUB_REMOTE=${GITHUB_FORK}/obspy
             export GITHUB_BRANCH=${GITHUB_LABEL#*:}
        # we're building a branch on the main repo
        else export GITHUB_REMOTE=$TRAVIS_REPO_SLUG
             export GITHUB_BRANCH=$TRAVIS_BRANCH
             export GITHUB_FORK=${TRAVIS_REPO_SLUG%/*}; fi \
      && echo "$GITHUB_REMOTE $GITHUB_FORK $GITHUB_BRANCH" \
      && if [ "$GITHUB_FORK" != "obspy" ]
          then git remote add $GITHUB_FORK git://github.com/$GITHUB_REMOTE; fi \
      && git fetch $GITHUB_FORK +refs/heads/$GITHUB_BRANCH \
      && git checkout -b tested_branch \
      && git branch --set-upstream-to=$GITHUB_FORK/$GITHUB_BRANCH \
      || echo
  - git branch -vv
  - git remote -vv
  - pip install --no-deps .
  - git status

script:
  # We change directories to make sure that python won't find the copy
  # of obspy in the source directory, see
  # https://github.com/numpy/numpy/blob/master/.travis.yml#L44
  - mkdir empty
  - cd empty
  # check if any additional modules should be tested (via github issue comments)
  - |
      if [ "$TRAVIS_PULL_REQUEST" != "false" ]
        # we're building a pull request, so check what modules should be tested
        then export MODULELIST=`python -c "from obspy_github_api import get_module_test_list; print('obspy.' + ',obspy.'.join(get_module_test_list($TRAVIS_PULL_REQUEST)))"`
             export MODULELISTSPACES=`python -c "from obspy_github_api import get_module_test_list; print(' '.join(get_module_test_list($TRAVIS_PULL_REQUEST)))"`
        # we're building a branch on the main repo, so test *all* modules
        else export MODULELIST=`python -c "from obspy.core.util import ALL_MODULES as MODULES; print('obspy.' + ',obspy.'.join(MODULES))"`
      fi
  - echo $MODULELIST
  - echo $MODULELISTSPACES
  # need to set IFS so that space-separated MODULELISTSPACES list is interpreted correctly by run_tests()
  - export IFS=" "
  # if not on a PR, i.e. running on a push to master or maintenance_XXX: test *all* modules
  - if [[ "$TRAVIS_PULL_REQUEST" == "false" ]]; then
      coverage run --rcfile=.coveragerc --source=${MODULELIST} -m obspy.scripts.runtests --no-flake8 --all -n travis-ci -r --ci-url="https://travis-ci.org/${TRAVIS_REPO_SLUG}/jobs/${TRAVIS_JOB_ID}";
    else
      coverage run --rcfile=.coveragerc --source=${MODULELIST} -m obspy.scripts.runtests --no-flake8 -n travis-ci -r --ci-url="https://travis-ci.org/${TRAVIS_REPO_SLUG}/jobs/${TRAVIS_JOB_ID}" --pr-url="https://github.com/obspy/obspy/pull/${TRAVIS_PULL_REQUEST}" $MODULELISTSPACES;
    fi;

after_script:
  # if coverage file was created, upload data to codecov
  - ls .coverage && codecov

notifications:
    email: false
