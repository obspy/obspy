language: c

branches:
  only:
    - master
    - /^maintenance_[0-9]+\.[0-9]+\.x$/

sudo: false

matrix:
  include:
    # do one build run with our minimum dependencies
    # (or, well, at least the lowest version number that is available through
    #  anaconda..)
    - os: linux
      env: PYTHON_VERSION=2.7 MINIMUM_DEPENDENCIES="True"
    - os: linux
      env: PYTHON_VERSION=2.7
    - os: linux
      env: PYTHON_VERSION=3.3
    - os: linux
      env: PYTHON_VERSION=3.4
    - os: linux
      env: PYTHON_VERSION=3.5
    - os: linux
      env: PYTHON_VERSION=3.5 ARCHITECTURE_32BIT="True"
      addons:
        apt:
          packages:
            # https://github.com/travis-ci/apt-package-whitelist/blob/master/ubuntu-precise
            - libstdc++6:i386
            - gcc-multilib
    - os: osx
      env: PYTHON_VERSION=2.7
    - os: osx
      env: PYTHON_VERSION=3.5

install:
  - if [[ "$TRAVIS_OS_NAME" == "osx" ]]; then
      export OS="MacOSX";
    else
      export OS="Linux";
    fi
  - |
      if [[ "$ARCHITECTURE_32BIT" == "True" ]]; then
        export ARCH=""
        # OPT is used by setuptools patches contained in newer numpy versions
        # used by obspy when running pip install --no-deps .
        export OPT="-m32"
        # workaround for sudo dpkg --add-architecture i386
        # be sure multiarch is the only file in this directory
        ls /etc/dpkg/dpkg.cfg.d/
        # multiarch must contain foreign-architecture i386. If not it will
        # error later and you need to do the following and add sudo: true
        #sudo sh -c "echo 'foreign-architecture i386' > /etc/dpkg/dpkg.cfg.d/multiarch"
        cat /etc/dpkg/dpkg.cfg.d/multiarch
      else
        export ARCH="_64"
      fi
  - if [[ "${PYTHON_VERSION:0:1}" == '2' ]]; then
      wget https://repo.continuum.io/miniconda/Miniconda-latest-${OS}-x86${ARCH}.sh -O miniconda.sh;
    else
      wget https://repo.continuum.io/miniconda/Miniconda3-latest-${OS}-x86${ARCH}.sh -O miniconda.sh;
    fi
  - bash miniconda.sh -b -p $HOME/miniconda
  - export PATH="$HOME/miniconda/bin:$PATH"
  - hash -r
  - conda config --set always_yes yes --set changeps1 no
  - conda update -q conda
  # Useful for debugging any issues with conda
  - conda info -a
  - |
      if [[ "$MINIMUM_DEPENDENCIES" == 'True' ]]; then
        NUMPY_VERSION=1.6.2
        SCIPY_VERSION=0.11.0
        MPL_VERSION=1.1.1
        # no basemap version works with this old numpy, so leave out
        BASEMAP=""
        PYPROJ="pyproj"
        # ancient matplotlib needs to be turned to AGG before anything else,
        # otherwise it tries to import incompatible version of Qt as a backend
        # and hick-ups..
        mkdir -p $HOME/.matplotlib
        echo 'backend:AGG' > $HOME/.matplotlib/matplotlibrc
      elif [[ "${PYTHON_VERSION}" == '3.3' ]]; then
        # newer package versions for 3.3 not available via anaconda
        NUMPY_VERSION=1.9.2
        SCIPY_VERSION=0.16.0
        MPL_VERSION=1.4.3
        BASEMAP="basemap=1.0.7"
        # no cartopy for py33 in conda-forge channel
        # anaconda doesn't provide pyproj for Python 3.3 anymore, looks like
        PYPROJ=""
      elif [[ "${PYTHON_VERSION:0:1}" == '3' ]]; then
        NUMPY_VERSION=1.10.4
        SCIPY_VERSION=0.17.0
        MPL_VERSION=1.5.1
        BASEMAP="basemap=1.0.7"
        PYPROJ="pyproj"
      else
        NUMPY_VERSION=1.10.4
        SCIPY_VERSION=0.17.0
        MPL_VERSION=1.5.1
        BASEMAP="basemap=1.0.7"
        PYPROJ="pyproj"
      fi
  # for now fix requests version, can be changed when a new requests is released (see #1599)
  - conda create -q -n test-environment
        python=$PYTHON_VERSION
        numpy=$NUMPY_VERSION
        scipy=$SCIPY_VERSION
        matplotlib=$MPL_VERSION
        $BASEMAP
        $PYPROJ
        future
        lxml
        decorator
        sqlalchemy
        mock
        nose
        gdal
        docopt
        coverage
        'requests<2.12'
        jsonschema
  - source activate test-environment
  # additional, optional packages that run some more tests but are not
  # available for all archs. "--no-update-dependencies" keeps other packages at
  # already installed version (ideally we should handle package versions
  # through pinning or an environment file..)
  - conda config --add channels conda-forge
  - conda install --no-update-dependencies m2crypto || true
  - conda install --no-update-dependencies cartopy || true
  # install packages not available via conda
  - pip install codecov
  - pip install geographiclib
  # current pyimgur stable release has a py3 incompatibility
  - pip install https://github.com/megies/PyImgur/archive/py3.zip
  # Always install the latest flake8 to get up-to-date formatting checks.
  - pip install flake8
  - pip freeze
  - pip install pep8-naming
  - pip install https://github.com/obspy/obspy_github_api/archive/0.7.0.zip
  - conda list
  # done installing dependencies
  - git version
  - git fetch origin --tags --unshallow
  - git remote add obspy git://github.com/obspy/obspy.git
  - git fetch obspy --tags
  - git status
  - git branch -vv
  - git remote -vv
  # try to set correct remote tracking branch (to get branch info in version number of reports at tests.obspy.org)
  - |
      if [ "$TRAVIS_PULL_REQUEST" != "false" ]
        # we're building a pull request, so we need to find out the fork it's coming from through github API
        then GITHUB_LABEL=`python -c "from urllib import urlopen; import json; print(json.loads(urlopen(\"https://api.github.com/repos/$TRAVIS_REPO_SLUG/pulls/$TRAVIS_PULL_REQUEST\").read()).get('head').get('label'))"`
             export GITHUB_FORK=${GITHUB_LABEL%:*}
             export GITHUB_REMOTE=${GITHUB_FORK}/obspy
             export GITHUB_BRANCH=${GITHUB_LABEL#*:}
        # we're building a branch on the main repo
        else export GITHUB_REMOTE=$TRAVIS_REPO_SLUG
             export GITHUB_BRANCH=$TRAVIS_BRANCH
             export GITHUB_FORK=${TRAVIS_REPO_SLUG%/*}; fi \
      && echo "$GITHUB_REMOTE $GITHUB_FORK $GITHUB_BRANCH" \
      && if [ "$GITHUB_FORK" != "obspy" ]
          then git remote add $GITHUB_FORK git://github.com/$GITHUB_REMOTE; fi \
      && git fetch $GITHUB_FORK +refs/heads/$GITHUB_BRANCH \
      && git checkout -b tested_branch \
      && git branch --set-upstream-to=$GITHUB_FORK/$GITHUB_BRANCH \
      || echo
  - git branch -vv
  - git remote -vv
  - pip install --no-deps .
  - git status

script:
  # We change directories to make sure that python won't find the copy
  # of obspy in the source directory, see
  # https://github.com/numpy/numpy/blob/master/.travis.yml#L44
  - mkdir empty
  - cd empty
  # check if any additional modules should be tested (via github issue comments)
  - |
      if [ "$TRAVIS_PULL_REQUEST" != "false" ]
        # we're building a pull request, so check what modules should be tested
        then export MODULELIST=`python -c "from obspy_github_api import get_module_test_list; print('obspy.' + ',obspy.'.join(get_module_test_list($TRAVIS_PULL_REQUEST)))"`
             export MODULELISTSPACES=`python -c "from obspy_github_api import get_module_test_list; print(' '.join(get_module_test_list($TRAVIS_PULL_REQUEST)))"`
        # we're building a branch on the main repo, so test *all* modules
        else export MODULELIST=`python -c "from obspy.core.util import ALL_MODULES as MODULES; print('obspy.' + ',obspy.'.join(MODULES))"`
      fi
  - echo $MODULELIST
  - echo $MODULELISTSPACES
  # need to set IFS so that space-separated MODULELISTSPACES list is interpreted correctly by run_tests()
  - export IFS=" "
  # if not on a PR, i.e. running on a push to master or maintenance_XXX: test *all* modules
  - if [[ "$TRAVIS_PULL_REQUEST" == "false" ]]; then
      coverage run --rcfile=.coveragerc --source=${MODULELIST} -m obspy.scripts.runtests --all -n travis-ci -r --ci-url="https://travis-ci.org/${TRAVIS_REPO_SLUG}/jobs/${TRAVIS_JOB_ID}";
    else
      coverage run --rcfile=.coveragerc --source=${MODULELIST} -m obspy.scripts.runtests -n travis-ci -r --ci-url="https://travis-ci.org/${TRAVIS_REPO_SLUG}/jobs/${TRAVIS_JOB_ID}" --pr-url="https://github.com/obspy/obspy/pull/${TRAVIS_PULL_REQUEST}" $MODULELISTSPACES;
    fi;

after_script:
  # if coverage file was created, upload data to codecov
  - ls .coverage && codecov

notifications:
    email: false
